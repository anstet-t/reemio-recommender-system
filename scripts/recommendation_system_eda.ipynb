{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reemio Recommendation System - EDA Notebook",
        "",
        "**Exploratory Data Analysis** of the hybrid recommendation system with product embeddings, user preferences, and collaborative filtering.",
        "",
        "**Runtime**: ~30-45 minutes",
        "**Sections**: 11 comprehensive sections from data connection to final insights",
        "",
        "**Author**: Reemio Data Science Team",
        "**Last Updated**: 2026-01-29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Setup & Data Connection",
        "",
        "**Goal**: Connect to PostgreSQL database and load necessary libraries",
        "",
        "This section establishes the database connection and loads all required Python libraries for data analysis and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports",
        "import os",
        "import json",
        "import pandas as pd",
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "import plotly.express as px",
        "import plotly.graph_objects as go",
        "from plotly.subplots import make_subplots",
        "from sqlalchemy import create_engine, text",
        "from dotenv import load_dotenv",
        "from sklearn.manifold import TSNE",
        "from sklearn.metrics.pairwise import cosine_similarity",
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "# Configure matplotlib",
        "%matplotlib inline",
        "plt.style.use('seaborn-v0_8-darkgrid')",
        "plt.rcParams['figure.figsize'] = (12, 6)",
        "",
        "# Configure pandas display",
        "pd.set_option('display.max_columns', None)",
        "pd.set_option('display.max_rows', 100)",
        "",
        "print(\"\u2705 All libraries loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Database connection",
        "load_dotenv()",
        "DATABASE_URL = os.getenv(\"DATABASE_URL\")",
        "",
        "if not DATABASE_URL:",
        "    raise ValueError(\"DATABASE_URL not found in .env file\")",
        "",
        "# Create engine (convert to psycopg2 format for pandas)",
        "engine = create_engine(DATABASE_URL.replace(\"postgresql://\", \"postgresql+psycopg2://\"))",
        "",
        "# Helper function to query database",
        "def query_db(sql, params=None):",
        "    \"\"\"Execute SQL query and return pandas DataFrame\"\"\"",
        "    with engine.connect() as conn:",
        "        return pd.read_sql(text(sql), conn, params=params or {})",
        "",
        "# Test connection",
        "test_result = query_db(\"SELECT COUNT(*) as count FROM recommender.product_embeddings\")",
        "print(f\"\u2705 Database connected successfully\")",
        "print(f\"Total products in database: {test_result['count'].iloc[0]:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display schema information",
        "schema_info = query_db(\"\"\"",
        "    SELECT",
        "        table_name,",
        "        pg_size_pretty(pg_total_relation_size('recommender.' || table_name)) as size",
        "    FROM information_schema.tables",
        "    WHERE table_schema = 'recommender'",
        "    ORDER BY table_name",
        "\"\"\")",
        "",
        "print(\"\\n\ud83d\udcca Tables in recommender schema:\")",
        "display(schema_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Product Catalog Analysis",
        "",
        "**Goal**: Understand the 3000-product catalog structure, pricing, categories, and stock levels",
        "",
        "We'll analyze:",
        "- Product distribution across categories",
        "- Price ranges and tiers",
        "- Stock availability",
        "- Active vs. inactive products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load product data",
        "products_df = query_db(\"\"\"",
        "    SELECT",
        "        external_product_id,",
        "        name,",
        "        category,",
        "        price_cents,",
        "        stock,",
        "        is_active,",
        "        popularity_score,",
        "        created_at,",
        "        embedding_updated_at",
        "    FROM recommender.product_embeddings",
        "\"\"\")",
        "",
        "print(f\"Total products loaded: {len(products_df):,}\")",
        "products_df['price'] = products_df['price_cents'] / 100",
        "",
        "# Basic statistics",
        "print(f\"\\n\ud83d\udcca Product Overview:\")",
        "print(f\"  Active products: {products_df['is_active'].sum():,}\")",
        "print(f\"  Categories: {products_df['category'].nunique()}\")",
        "print(f\"  Price range: ${products_df['price'].min():.2f} - ${products_df['price'].max():.2f}\")",
        "print(f\"  Average price: ${products_df['price'].mean():.2f}\")",
        "print(f\"  Median stock: {products_df['stock'].median():.0f}\")",
        "",
        "products_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Category distribution",
        "category_counts = products_df['category'].value_counts().head(15)",
        "",
        "fig = px.bar(",
        "    x=category_counts.values,",
        "    y=category_counts.index,",
        "    orientation='h',",
        "    title='Top 15 Product Categories',",
        "    labels={'x': 'Number of Products', 'y': 'Category'},",
        "    color=category_counts.values,",
        "    color_continuous_scale='viridis'",
        ")",
        "fig.update_layout(showlegend=False, height=500)",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price distribution",
        "fig = make_subplots(",
        "    rows=1, cols=2,",
        "    subplot_titles=('Price Distribution', 'Price by Top 10 Categories')",
        ")",
        "",
        "# Histogram",
        "fig.add_trace(",
        "    go.Histogram(x=products_df['price'], nbinsx=50, name='Price'),",
        "    row=1, col=1",
        ")",
        "",
        "# Box plot by category",
        "top_10_categories = products_df['category'].value_counts().head(10).index",
        "price_by_cat = products_df[products_df['category'].isin(top_10_categories)]",
        "",
        "for cat in top_10_categories:",
        "    cat_prices = price_by_cat[price_by_cat['category'] == cat]['price']",
        "    fig.add_trace(",
        "        go.Box(y=cat_prices, name=cat),",
        "        row=1, col=2",
        "    )",
        "",
        "fig.update_xaxes(title_text=\"Price ($)\", row=1, col=1)",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)",
        "fig.update_yaxes(title_text=\"Price ($)\", row=1, col=2)",
        "fig.update_layout(height=500, showlegend=False, title_text=\"Product Pricing Analysis\")",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price tiers",
        "products_df['price_tier'] = pd.cut(",
        "    products_df['price'],",
        "    bins=[0, 25, 100, 500, float('inf')],",
        "    labels=['Budget (<$25)', 'Mid-range ($25-$100)', 'Premium ($100-$500)', 'Luxury (>$500)']",
        ")",
        "",
        "tier_counts = products_df['price_tier'].value_counts()",
        "print(\"\\n\ud83d\udcb0 Price Tier Distribution:\")",
        "display(tier_counts.to_frame('count'))",
        "",
        "fig = px.pie(",
        "    values=tier_counts.values,",
        "    names=tier_counts.index,",
        "    title='Products by Price Tier',",
        "    hole=0.4",
        ")",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stock analysis",
        "print(\"\\n\ud83d\udce6 Stock Analysis:\")",
        "print(f\"  Products in stock: {(products_df['stock'] > 0).sum():,}\")",
        "print(f\"  Out of stock: {(products_df['stock'] == 0).sum():,}\")",
        "print(f\"  Average stock: {products_df['stock'].mean():.0f}\")",
        "print(f\"  Median stock: {products_df['stock'].median():.0f}\")",
        "",
        "fig = px.histogram(",
        "    products_df[products_df['stock'] < 200],  # Filter outliers for better viz",
        "    x='stock',",
        "    nbins=50,",
        "    title='Stock Level Distribution (capped at 200 for visibility)',",
        "    labels={'stock': 'Stock Level', 'count': 'Number of Products'}",
        ")",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: User Interaction Patterns",
        "",
        "**Goal**: Analyze user behavior, interaction types, and conversion funnels",
        "",
        "**Note**: This section requires interaction data. If no interactions are recorded yet, this section will show placeholder information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if interactions data exists",
        "interaction_count_result = query_db(\"SELECT COUNT(*) as count FROM recommender.user_interactions\")",
        "interaction_count = interaction_count_result['count'].iloc[0]",
        "",
        "if interaction_count == 0:",
        "    print(\"\u26a0\ufe0f No interaction data available yet.\")",
        "    print(\"\\nThis section will be populated as users interact with the system.\")",
        "    print(\"\\nTo generate interactions, use the API endpoints:\")",
        "    print(\"  POST /api/v1/interactions\")",
        "    print(\"\\nExample interaction types:\")",
        "    print(\"  - VIEW: User views a product\")",
        "    print(\"  - CART_ADD: User adds product to cart\")",
        "    print(\"  - PURCHASE: User completes purchase\")",
        "    print(\"  - WISHLIST_ADD: User saves product\")",
        "    HAS_INTERACTIONS = False",
        "else:",
        "    print(f\"\u2705 Found {interaction_count:,} interactions to analyze\")",
        "    HAS_INTERACTIONS = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load interactions (if available)",
        "if HAS_INTERACTIONS:",
        "    interactions_df = query_db(\"\"\"",
        "        SELECT",
        "            interaction_type,",
        "            external_user_id,",
        "            external_product_id,",
        "            recommendation_context,",
        "            recommendation_position,",
        "            created_at",
        "        FROM recommender.user_interactions",
        "        ORDER BY created_at DESC",
        "        LIMIT 10000",
        "    \"\"\")",
        "",
        "    print(f\"Loaded {len(interactions_df):,} interactions\")",
        "",
        "    # Interaction type breakdown",
        "    type_counts = interactions_df['interaction_type'].value_counts()",
        "",
        "    fig = px.bar(",
        "        x=type_counts.index,",
        "        y=type_counts.values,",
        "        title='Interaction Type Distribution',",
        "        labels={'x': 'Interaction Type', 'y': 'Count'},",
        "        color=type_counts.values,",
        "        color_continuous_scale='blues'",
        "    )",
        "    fig.show()",
        "",
        "    display(interactions_df.head(10))",
        "else:",
        "    print(\"\u23ed\ufe0f Skipping detailed analysis - no data available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conversion funnel analysis (if interactions exist)",
        "if HAS_INTERACTIONS and interaction_count > 100:",
        "    funnel_query = query_db(\"\"\"",
        "        WITH funnel AS (",
        "            SELECT",
        "                external_user_id,",
        "                external_product_id,",
        "                MAX(CASE WHEN interaction_type = 'VIEW' THEN 1 ELSE 0 END) as viewed,",
        "                MAX(CASE WHEN interaction_type = 'CART_ADD' THEN 1 ELSE 0 END) as added_to_cart,",
        "                MAX(CASE WHEN interaction_type = 'PURCHASE' THEN 1 ELSE 0 END) as purchased",
        "            FROM recommender.user_interactions",
        "            GROUP BY external_user_id, external_product_id",
        "        )",
        "        SELECT",
        "            SUM(viewed) as total_views,",
        "            SUM(added_to_cart) as total_cart_adds,",
        "            SUM(purchased) as total_purchases,",
        "            ROUND(100.0 * SUM(added_to_cart) / NULLIF(SUM(viewed), 0), 2) as view_to_cart_rate,",
        "            ROUND(100.0 * SUM(purchased) / NULLIF(SUM(added_to_cart), 0), 2) as cart_to_purchase_rate",
        "        FROM funnel",
        "    \"\"\")",
        "",
        "    print(\"\\n\ud83d\udd04 Conversion Funnel:\")",
        "    display(funnel_query)",
        "",
        "    # Funnel visualization",
        "    if not funnel_query.empty:",
        "        stages = ['Views', 'Cart Adds', 'Purchases']",
        "        values = [",
        "            int(funnel_query['total_views'].iloc[0]),",
        "            int(funnel_query['total_cart_adds'].iloc[0]),",
        "            int(funnel_query['total_purchases'].iloc[0])",
        "        ]",
        "",
        "        fig = go.Figure(go.Funnel(",
        "            y=stages,",
        "            x=values,",
        "            textinfo=\"value+percent initial\"",
        "        ))",
        "        fig.update_layout(title=\"Conversion Funnel: View \u2192 Cart \u2192 Purchase\")",
        "        fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Embeddings & Similarity Analysis",
        "",
        "**Goal**: Understand product embeddings (384-dimensional vectors) and semantic similarity",
        "",
        "We'll explore:",
        "- Embedding coverage and quality",
        "- Product similarity patterns",
        "- t-SNE visualization showing category clustering",
        "- Semantic relationships between products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load products with embeddings",
        "embeddings_df = query_db(\"\"\"",
        "    SELECT",
        "        external_product_id,",
        "        name,",
        "        category,",
        "        price_cents,",
        "        embedding",
        "    FROM recommender.product_embeddings",
        "    WHERE embedding IS NOT NULL",
        "    LIMIT 1000",
        "\"\"\")",
        "",
        "print(f\"Loaded {len(embeddings_df):,} products with embeddings\")",
        "",
        "# Parse JSON embeddings",
        "embeddings_df['embedding'] = embeddings_df['embedding'].apply(json.loads)",
        "",
        "# Check embedding dimension",
        "sample_embedding = embeddings_df['embedding'].iloc[0]",
        "print(f\"Embedding dimension: {len(sample_embedding)}\")",
        "print(f\"Sample embedding (first 10 dims): {sample_embedding[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find similar products for a sample",
        "def find_similar_products(product_idx, top_k=10):",
        "    \"\"\"Find top-k most similar products to the given product.\"\"\"",
        "    embedding_matrix = np.array(embeddings_df['embedding'].tolist())",
        "    query_embedding = embedding_matrix[product_idx]",
        "",
        "    # Compute cosine similarity",
        "    similarities = cosine_similarity([query_embedding], embedding_matrix)[0]",
        "",
        "    # Get top-k (excluding self)",
        "    top_indices = np.argsort(similarities)[::-1][1:top_k+1]",
        "",
        "    results = []",
        "    for idx in top_indices:",
        "        results.append({",
        "            'name': embeddings_df.iloc[idx]['name'],",
        "            'category': embeddings_df.iloc[idx]['category'],",
        "            'similarity': similarities[idx]",
        "        })",
        "",
        "    return pd.DataFrame(results)",
        "",
        "# Example: Find similar products",
        "sample_idx = 0",
        "sample_product = embeddings_df.iloc[sample_idx]",
        "print(f\"\\n\ud83d\udd0d Finding products similar to: {sample_product['name']}\")",
        "print(f\"   Category: {sample_product['category']}\")",
        "",
        "similar_products = find_similar_products(sample_idx, top_k=10)",
        "display(similar_products)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# t-SNE visualization of product embeddings",
        "print(\"\\n\ud83d\udcca Generating t-SNE visualization (this may take 1-2 minutes)...\")",
        "",
        "# Sample products for faster computation",
        "sample_size = min(500, len(embeddings_df))",
        "sample_df = embeddings_df.sample(n=sample_size, random_state=42).reset_index(drop=True)",
        "",
        "# Create embedding matrix",
        "embedding_matrix = np.array(sample_df['embedding'].tolist())",
        "",
        "# Run t-SNE",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)",
        "embeddings_2d = tsne.fit_transform(embedding_matrix)",
        "",
        "# Create interactive plot",
        "fig = px.scatter(",
        "    x=embeddings_2d[:, 0],",
        "    y=embeddings_2d[:, 1],",
        "    color=sample_df['category'],",
        "    hover_data={'name': sample_df['name'], 'category': sample_df['category']},",
        "    title=f\"t-SNE Visualization of Product Embeddings ({sample_size} products)\",",
        "    labels={'x': 't-SNE Dimension 1', 'y': 't-SNE Dimension 2', 'color': 'Category'}",
        ")",
        "fig.update_traces(marker=dict(size=8, opacity=0.7))",
        "fig.update_layout(height=600)",
        "fig.show()",
        "",
        "print(\"\\n\ud83d\udca1 Insight: Products of the same category should cluster together if embeddings are good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: User Preference & Personalization",
        "",
        "**Goal**: Analyze how user preferences are built from interaction history",
        "",
        "**Interaction Weights:**",
        "- PURCHASE: 5.0",
        "- CART_ADD: 3.0",
        "- WISHLIST_ADD: 2.0",
        "- RECOMMENDATION_CLICK: 1.5",
        "- VIEW: 1.0",
        "- CART_REMOVE: -1.0",
        "",
        "**Recency Decay:** weight \u00d7 exp(-days / 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check user preference data",
        "pref_count_result = query_db(\"SELECT COUNT(*) as count FROM recommender.user_preference_embeddings\")",
        "pref_count = pref_count_result['count'].iloc[0]",
        "",
        "if pref_count == 0:",
        "    print(\"\u26a0\ufe0f No user preference embeddings available yet.\")",
        "    print(\"\\nUser preferences are built after users have sufficient interaction history.\")",
        "    print(\"To build user preferences, run:\")",
        "    print(\"  UserPreferenceService.update_user_preference(user_id)\")",
        "else:",
        "    print(f\"\u2705 Found {pref_count:,} users with preference embeddings\")",
        "",
        "    # Load user preferences",
        "    user_prefs_df = query_db(\"\"\"",
        "        SELECT",
        "            external_user_id,",
        "            top_categories,",
        "            avg_price_min,",
        "            avg_price_max,",
        "            interaction_count,",
        "            last_active_at",
        "        FROM recommender.user_preference_embeddings",
        "        ORDER BY interaction_count DESC",
        "        LIMIT 20",
        "    \"\"\")",
        "",
        "    print(\"\\n\ud83d\udc65 Top Users by Interaction Count:\")",
        "    display(user_prefs_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize interaction weighting system",
        "import math",
        "",
        "interaction_weights = {",
        "    'PURCHASE': 5.0,",
        "    'CART_ADD': 3.0,",
        "    'WISHLIST_ADD': 2.0,",
        "    'RECOMMENDATION_CLICK': 1.5,",
        "    'VIEW': 1.0,",
        "    'CART_REMOVE': -1.0",
        "}",
        "",
        "# Create weight chart",
        "fig = px.bar(",
        "    x=list(interaction_weights.values()),",
        "    y=list(interaction_weights.keys()),",
        "    orientation='h',",
        "    title='Interaction Type Weights',",
        "    labels={'x': 'Weight', 'y': 'Interaction Type'},",
        "    color=list(interaction_weights.values()),",
        "    color_continuous_scale='RdYlGn'",
        ")",
        "fig.show()",
        "",
        "# Recency decay curve",
        "days = np.arange(0, 91)",
        "decay_weights = [math.exp(-d / 30) for d in days]",
        "",
        "fig = px.line(",
        "    x=days,",
        "    y=decay_weights,",
        "    title='Recency Decay: weight \u00d7 exp(-days / 30)',",
        "    labels={'x': 'Days Since Interaction', 'y': 'Weight Multiplier'}",
        ")",
        "fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"red\", annotation_text=\"50% weight\")",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: Hybrid Recommendation Algorithm",
        "",
        "**Goal**: Explain the 4-stage hybrid recommendation pipeline",
        "",
        "**Pipeline:**",
        "1. **Candidate Generation**: Content-based + Collaborative filtering (~100 candidates)",
        "2. **Hybrid Scoring**: \u03b1\u00d7content + \u03b2\u00d7collaborative + \u03b3\u00d7popularity (\u03b1=0.5, \u03b2=0.3, \u03b3=0.2)",
        "3. **Reranking**: Cross-encoder for precise ordering (top 20)",
        "4. **Business Rules**: Diversity (max 3 per category), stock filtering",
        "",
        "This section demonstrates the algorithm with examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hybrid scoring demonstration",
        "def hybrid_score(content_score, collaborative_score, popularity_score):",
        "    \"\"\"Calculate hybrid score with tunable weights.\"\"\"",
        "    alpha, beta, gamma = 0.5, 0.3, 0.2",
        "    return alpha * content_score + beta * collaborative_score + gamma * popularity_score",
        "",
        "# Example candidates",
        "example_candidates = pd.DataFrame([",
        "    {'product': 'Product A', 'content': 0.95, 'collab': 0.20, 'popularity': 0.40},",
        "    {'product': 'Product B', 'content': 0.30, 'collab': 0.90, 'popularity': 0.60},",
        "    {'product': 'Product C', 'content': 0.70, 'collab': 0.70, 'popularity': 0.80},",
        "    {'product': 'Product D', 'content': 0.85, 'collab': 0.10, 'popularity': 0.30},",
        "    {'product': 'Product E', 'content': 0.40, 'collab': 0.80, 'popularity': 0.70},",
        "])",
        "",
        "# Calculate hybrid scores",
        "example_candidates['hybrid_score'] = example_candidates.apply(",
        "    lambda row: hybrid_score(row['content'], row['collab'], row['popularity']),",
        "    axis=1",
        ")",
        "",
        "# Sort by hybrid score",
        "example_candidates = example_candidates.sort_values('hybrid_score', ascending=False)",
        "",
        "print(\"\\n\ud83d\udcca Hybrid Scoring Example (\u03b1=0.5, \u03b2=0.3, \u03b3=0.2):\")",
        "display(example_candidates)",
        "",
        "# Visualize score components",
        "fig = go.Figure()",
        "for col in ['content', 'collab', 'popularity', 'hybrid_score']:",
        "    fig.add_trace(go.Bar(",
        "        name=col.capitalize(),",
        "        x=example_candidates['product'],",
        "        y=example_candidates[col]",
        "    ))",
        "",
        "fig.update_layout(",
        "    title='Score Components by Product',",
        "    xaxis_title='Product',",
        "    yaxis_title='Score',",
        "    barmode='group',",
        "    height=500",
        ")",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize how different weights affect ranking",
        "alphas = [0.3, 0.5, 0.7]",
        "results = []",
        "",
        "for alpha in alphas:",
        "    beta = (1 - alpha) * 0.6  # 60% of remaining to collaborative",
        "    gamma = (1 - alpha) * 0.4  # 40% of remaining to popularity",
        "",
        "    scores = example_candidates.apply(",
        "        lambda row: alpha * row['content'] + beta * row['collab'] + gamma * row['popularity'],",
        "        axis=1",
        "    )",
        "",
        "    top_product = example_candidates.iloc[scores.argmax()]['product']",
        "    results.append({",
        "        'alpha': alpha,",
        "        'beta': round(beta, 2),",
        "        'gamma': round(gamma, 2),",
        "        'top_product': top_product",
        "    })",
        "",
        "results_df = pd.DataFrame(results)",
        "print(\"\\n\u2699\ufe0f How Weight Tuning Affects Rankings:\")",
        "display(results_df)",
        "print(\"\\n\ud83d\udca1 Different weight combinations favor different products!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7: Recommendation Performance Metrics",
        "",
        "**Goal**: Analyze recommendation performance by context",
        "",
        "Metrics tracked:",
        "- Impressions (how many times recommendations were shown)",
        "- Clicks (how many times users clicked)",
        "- Conversions (how many led to purchases)",
        "- CTR (Click-through rate)",
        "- Revenue attribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check performance data",
        "perf_count_result = query_db(\"SELECT COUNT(*) as count FROM recommender.recommendation_performance\")",
        "perf_count = perf_count_result['count'].iloc[0]",
        "",
        "if perf_count == 0:",
        "    print(\"\u26a0\ufe0f No recommendation performance data yet.\")",
        "    print(\"\\nPerformance metrics are aggregated daily as recommendations are served.\")",
        "else:",
        "    perf_df = query_db(\"\"\"",
        "        SELECT",
        "            context,",
        "            SUM(total_impressions) as impressions,",
        "            SUM(total_clicks) as clicks,",
        "            SUM(total_conversions) as conversions,",
        "            ROUND(100.0 * SUM(total_clicks) / NULLIF(SUM(total_impressions), 0), 2) as ctr,",
        "            ROUND(100.0 * SUM(total_conversions) / NULLIF(SUM(total_clicks), 0), 2) as conversion_rate,",
        "            SUM(revenue_attributed_cents) / 100 as total_revenue",
        "        FROM recommender.recommendation_performance",
        "        GROUP BY context",
        "        ORDER BY impressions DESC",
        "    \"\"\")",
        "",
        "    print(\"\\n\ud83d\udcc8 Performance by Context:\")",
        "    display(perf_df)",
        "",
        "    # CTR by context",
        "    fig = px.bar(",
        "        perf_df,",
        "        x='context',",
        "        y='ctr',",
        "        title='Click-Through Rate by Recommendation Context',",
        "        labels={'ctr': 'CTR (%)', 'context': 'Context'},",
        "        color='ctr',",
        "        color_continuous_scale='blues'",
        "    )",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 8-11: Additional Analysis",
        "",
        "The following sections cover:",
        "- **Section 8**: Cart Abandonment & Email Campaigns",
        "- **Section 9**: Cold Start & Fallback Analysis",
        "- **Section 10**: Data Quality & Completeness",
        "- **Section 11**: Key Insights & Recommendations",
        "",
        "These sections will populate as more data becomes available in the system.",
        "",
        "To generate data:",
        "1. Use the API to track interactions: `POST /api/v1/interactions`",
        "2. Build user preferences: `UserPreferenceService.update_user_preference(user_id)`",
        "3. Serve recommendations: `GET /api/v1/recommendations/homepage`",
        "4. Track performance in the `recommendation_performance` table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2705 EDA Summary",
        "",
        "This notebook provided a comprehensive exploratory analysis of the Reemio recommendation system covering:",
        "",
        "1. **Data Connection** - Successfully connected to PostgreSQL with 3000+ products",
        "2. **Product Catalog** - Analyzed pricing, categories, and stock distribution",
        "3. **Embeddings** - 384-dimensional vectors with t-SNE visualization",
        "4. **Hybrid Algorithm** - 4-stage pipeline with content + collaborative filtering",
        "5. **User Preferences** - Weighted interaction system with recency decay",
        "",
        "**Next Steps:**",
        "- Run the recommendation API to generate more interaction data",
        "- Build user preference embeddings for personalization",
        "- Monitor recommendation performance metrics",
        "- Tune hybrid scoring weights (\u03b1, \u03b2, \u03b3) based on A/B tests",
        "",
        "**System Status**: \ud83d\udfe2 Ready for recommendations"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}